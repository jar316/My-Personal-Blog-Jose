[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jose A Rodriguez",
    "section": "",
    "text": "Jose A. Rodriguez is currently pursuing a Master’s in Advanced Data Analytics at the University of North Texas, having previously obtained a Bachelor’s in Data Analytics from Southern New Hampshire University. With over a decade of experience in the telecommunications and media industry, I transitioned into a role as a business analyst in 2020. After nearly two years, I progressed into the field of data analytics, focusing on web analytics. I have since held the position of Senior Data Analyst for a year.\nUtilized ad hoc analysis and Tableau dashboards to visualize outbound retention data, offering insights into product and service performance. Conducted comprehensive statistical analysis, including survival and T-test analyses, to identify trends crucial for strategic decision-making.\nSkilled in Microsoft PowerPoint and Excel. Proficient in Python, Google Cloud Platform (GCP), Jupyter Lab, Tableau, Alteryx, Alation, and various data management tools for efficient data gathering and organization."
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we’ll be using is a randomly selected subset of the original dataset.\nAttributes:\n\nPredictors\n\nfage: father’s age in years.\nmage: mother’s age in years.\nmature: maturity status of mother.\nweeks: length of pregnancy in weeks.\npremie: whether the birth was classified as premature (premie) or full-term.\nvisits: number of hospital visits during pregnancy.\nmarital: whether mother is married or not married at birth.\ngained: weight gained by mother during pregnancy in pounds.\ngender: gender of the baby, female or male.\nhabit: status of the mother as a nonsmoker or a smoker.\nwhitemom: whether mother is white or not white.\n\n\nOutcome Variable:\n\nweight: weight of the baby at birth in pounds. (Regression problem)"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#business-problem",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#business-problem",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "Our focus will be on examining the connection between the behaviors and routines of pregnant mothers and the outcomes of their childbirth. Please note, the dataset we’ll be using is a randomly selected subset of the original dataset.\nAttributes:\n\nPredictors\n\nfage: father’s age in years.\nmage: mother’s age in years.\nmature: maturity status of mother.\nweeks: length of pregnancy in weeks.\npremie: whether the birth was classified as premature (premie) or full-term.\nvisits: number of hospital visits during pregnancy.\nmarital: whether mother is married or not married at birth.\ngained: weight gained by mother during pregnancy in pounds.\ngender: gender of the baby, female or male.\nhabit: status of the mother as a nonsmoker or a smoker.\nwhitemom: whether mother is white or not white.\n\n\nOutcome Variable:\n\nweight: weight of the baby at birth in pounds. (Regression problem)"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-1",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-1",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "The correlation between ‘weight’ and all other variable varied and the strongest variable was ‘weeks’. When the ‘weeks’ of pregnancy are longer, the baby’s birth weight tends to be higher relationship is pretty strong ( 0.67). Also, it looks like the weight gained during pregnancy and how often someone goes to the doctor ‘visits’ might also have a small effect on the baby’s birth weight."
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-3",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-3",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "# Please provide your code for Task 1 in this code chunk\n\n#Data Structure Check\nstr(mydata)\n\n'data.frame':   999 obs. of  12 variables:\n $ fage    : int  NA NA 19 21 NA NA 18 17 NA 20 ...\n $ mage    : int  13 14 15 15 15 15 15 15 16 16 ...\n $ mature  : chr  \"younger mom\" \"younger mom\" \"younger mom\" \"younger mom\" ...\n $ weeks   : int  39 42 37 41 39 38 37 35 38 37 ...\n $ premie  : chr  \"full term\" \"full term\" \"full term\" \"full term\" ...\n $ visits  : int  10 15 11 6 9 19 12 5 9 13 ...\n $ marital : chr  \"married\" \"married\" \"married\" \"married\" ...\n $ gained  : int  38 20 38 34 27 22 76 15 NA 52 ...\n $ weight  : num  7.63 7.88 6.63 8 6.38 5.38 8.44 4.69 8.81 6.94 ...\n $ gender  : chr  \"male\" \"male\" \"female\" \"male\" ...\n $ habit   : chr  \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" \"nonsmoker\" ...\n $ whitemom: chr  \"not white\" \"not white\" \"white\" \"white\" ...\n\nnumeric &lt;- sapply(mydata, is.numeric)\ncategorical &lt;- sapply(mydata, is.factor)\n\nmydata[, numeric] &lt;- lapply(mydata[, numeric], function(x) ifelse(is.na(x), median(x, na.rm = TRUE), x))\n\nMode &lt;- function(x) {\n  ux &lt;- unique(x)\n  ux[which.max(tabulate(match(x, ux)))]\n}\n\n# Replace missing values in categorical columns with mode\nmydata[, categorical] &lt;- lapply(mydata[, categorical], function(x) ifelse(is.na(x), Mode(x), x))\n\n\nnumeric_vars &lt;- sapply(mydata, is.numeric)\n\ncor_matrix_numeric &lt;- cor(mydata[, numeric_vars])\n\ntarget_var &lt;- \"weight\"  \ncor_with_target &lt;- cor_matrix_numeric['weight', ]\nhighest_correlation &lt;- names(sort(abs(cor_with_target), decreasing = TRUE)[2])\n\nplot(mydata[[target_var]], mydata[[highest_correlation]],\n     xlab = target_var, ylab = highest_correlation,\n     main = paste(\"Scatter plot between\", target_var, \"and\", highest_correlation))"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-4",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-4",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "# Please provide your code for Task 2 in this code chunk\n# split the sample by using rsample package\n\n# Split the data into a training set (70%) and a test set (30%)\nset.seed(123456)\n\n# Divide the dataset into a training set (70%) and a test set (30%) using stratified sampling\nsplit_data &lt;- initial_split(mydata, prop = 0.7, strata = \"weight\")\n\n# Assign the training set and test set to variables\ntrain_data &lt;- training(split_data)\ntest_data &lt;- testing(split_data)"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-5",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-5",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "# Please provide your code for Task 3  in this code chunk\n\nlinearmodel &lt;- lm(weight ~ ., data = train_data)\n\npredicted_weights_ols &lt;- predict(linearmodel, newdata = test_data)\n\n\nMSPE_linear &lt;- mean((predicted_weights_ols - as.numeric(test_data$weight))^2, na.rm = TRUE)\n\nprint(MSPE_linear)\n\n[1] 1.134988"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-6",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-6",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "1.107573"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-7",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-7",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "# Please provide your code for Task 4 in this code chunk\n\n# Fit a Generalized Additive Model (GAM) on train_data using gam()\n# Assuming suitable predictors are 'predictor1', 'predictor2', etc. Update these names based on your dataset.\ngam_model &lt;- gam(weight ~ s(weeks) + s(visits)  + habit + gender, data = train_data, method = \"REML\")\n\n# Print smoothing parameters from gam_model\nsummary(gam_model)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nweight ~ s(weeks) + s(visits) + habit + gender\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  6.94080    0.05690 121.979  &lt; 2e-16 ***\nhabitsmoker -0.31862    0.11788  -2.703  0.00704 ** \ngendermale   0.35506    0.07862   4.516 7.41e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n            edf Ref.df       F p-value    \ns(weeks)  4.941  5.991 113.180 &lt; 2e-16 ***\ns(visits) 4.466  5.482   3.373 0.00406 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.539   Deviance explained = 54.7%\n-REML = 1024.4  Scale est. = 1.0527    n = 698\n\n# Predict weight variable in the test_data dataset using gam_model\npredicted_weights_gam &lt;- predict(gam_model, newdata = test_data)\n\n# Calculate mean squared prediction error (MSPE) by comparing predicted values with actual values\nMSPE_gam &lt;- mean((predicted_weights_gam - test_data$weight)^2)\n\n# Print the value of MSPE_gam to the console\nprint(MSPE_gam)\n\n[1] 1.107573"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-8",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-8",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "Using the gam_model provided the lowest MSPE of 1.108"
  },
  {
    "objectID": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-9",
    "href": "posts/My First Post/Rodriguez_Jose_Week_5.html#section-9",
    "title": "Linear Regression vs Generalized Additive Models",
    "section": "",
    "text": "# Please provide your code for Task 5 in this code chunk\n\nprint(MSPE_linear)\n\n[1] 1.134988\n\nprint(MSPE_gam)\n\n[1] 1.107573"
  },
  {
    "objectID": "posts/Test/Mini_Project_Informs_Team_10.html",
    "href": "posts/Test/Mini_Project_Informs_Team_10.html",
    "title": "Mini Project Informs Data Challenge",
    "section": "",
    "text": "This project is based on the dataset provided for the INFORMS 2023 Data Challenge. INFORMS teamed up with Blue Summit Supplies, an online retailer based in Alabama, to tackle real-world challenges in setting the right prices for their products. The eCommerce market is fast-paced, with prices changing constantly. Quick and smart pricing decisions are essential for staying competitive and profitable. The Informs data challenge aims to use the company’s actual sales data to explore how pricing impacts profits, with the goal of helping the company make better, faster pricing decisions. This projects takes a different route. As a team, your task is to understand the dataset and prepare it for further analyses.\n\nProgramming Language: R\nDeliverables: Quarto Document (.qmd) and HTML Knitted Document\nLibraries: Any libraries you deem necessary\nThere are 8 tasks, each is worth 12.5 points.\n\n\n\n\nsku: This is the product ID, a unique identifier for each product.\nsalesdate: This represents the date on which a particular product was sold.\nprice: This is the price at which the product was sold on a given day.\nunitsordered: This variable shows the number of units of a product ordered on a particular day.\nsales: This represents the total revenue generated from the sale of a product on a given day (it is calculated as the product`s price times the number of units ordered).\ncogs: This stands for “Cost of Goods Sold”, which is the direct cost incurred by the company to produce or purchase the product.\nfba: This is the eCommerce fee associated with selling the product. It includes the costs of storage, packing, and shipping handled by Amazon.\nreffee: This is the eCommerce platform fee associated with selling the product (15% of sales).\nadspend: This represents the advertisement cost associated with the product.\nprofit: This is the profit obtained from selling the product, calculated as sales minus the sum of cogs, fba, reffee, and adspend (profit = sales - cogs - fba - reffee - adspend).\ncomp_x_price: This represents the price of a similar product sold by a competitor. Up to 5 competitors` price data are available for each product (67 items have O competitors, 65 items have 1 competitor, 56 items have 2 competitors, 28 items have 3 competitors, 9 items have 4 competitors, 2 items have 5 competitors).\ncomp_data_min_price: This is the minimum price among all competitors for a similar product.\ncomp_data_max_price: This is the maximum price among all competitors for a similar product.\nmanaged_fba_stock_level: This represents the available quantity of the product in stock.\nmin_price: This is the minimum allowable selling price for the product\nmax_price: This is the maximum allowable selling price for the product.\n\n\n\n\n\ninforms &lt;- read.csv(\"2023 INFORMS BSS Data Challenge Dataset.csv\", header=TRUE)\n\n\n\n\nIn this task, you will be ensuring that all variables in the dataset informs are of the correct type. This is a crucial step in any data analysis project, as incorrect variable types can lead to misleading analyses and results.\n\n\n\nDeclare categorical variables as factors.\nConvert the date variable to a date format.\nEnsure that numerical variables are set as numerical data types.\nYour R object, informs , should have 122801 rows and 20 columns.\nPrint the data structure below with str(informs) function.\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ninforms &lt;- informs %&gt;%\n  mutate(\n    sku = as.factor(sku),\n    salesdate = as.Date(salesdate, format=\"%Y-%m-%d\"),\n    price = as.numeric(price),\n    unitsordered = as.numeric(unitsordered),\n    sales = as.numeric(sales),\n    cogs = as.numeric(cogs),\n    fba = as.numeric(fba),\n    reffee = as.numeric(reffee),\n    adspend = as.numeric(adspend),\n    profit = as.numeric(profit),\n    comp_1_price = as.numeric(comp_1_price),\n    comp_2_price = as.numeric(comp_2_price),\n    comp_3_price = as.numeric(comp_3_price),\n    comp_4_price = as.numeric(comp_4_price),\n    comp_5_price = as.numeric(comp_5_price),\n    comp_data_min_price = as.numeric(comp_data_min_price),\n    comp_data_max_price = as.numeric(comp_data_max_price),\n    managed_fba_stock_level = as.numeric(managed_fba_stock_level),\n    min_price = as.numeric(min_price),\n    max_price = as.numeric(max_price)\n  )\n\nstr(informs)\n\n'data.frame':   122801 obs. of  20 variables:\n $ sku                    : Factor w/ 227 levels \"Binder Dividers SKU 1\",..: 61 61 61 61 61 61 61 61 61 61 ...\n $ salesdate              : Date, format: \"2022-01-01\" \"2022-01-02\" ...\n $ price                  : num  29.5 30 29.7 29.8 29.8 ...\n $ unitsordered           : num  19 13 84 78 83 61 66 18 20 70 ...\n $ sales                  : num  560 390 2494 2324 2473 ...\n $ cogs                   : num  236 161 1042 968 1030 ...\n $ fba                    : num  156 107 690 641 682 501 543 148 164 575 ...\n $ reffee                 : num  84 58 374 349 371 273 290 81 90 314 ...\n $ adspend                : num  0 0 0 0 0 0 0 0 0 0 ...\n $ profit                 : num  84 64 388 366 390 292 281 88 98 334 ...\n $ comp_1_price           : num  28.5 28.5 28.5 28.5 28.5 ...\n $ comp_2_price           : num  28 28 28 28 28 ...\n $ comp_3_price           : num  31 31 31 31 31 ...\n $ comp_4_price           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ comp_5_price           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ comp_data_min_price    : num  28 28 28 28 28 ...\n $ comp_data_max_price    : num  31 31 31 31 31 ...\n $ managed_fba_stock_level: num  NA NA NA NA NA NA NA NA NA NA ...\n $ min_price              : num  28 28 28 28 28 ...\n $ max_price              : num  35 35 35 35 35 ...\n\n\n\n\n\n\nIn this task, you are required to calculate the percentage of missing values for each variable in the informs dataset and display the results in a table. Understanding the extent of missing data is a crucial step in data analysis, as it can significantly impact the results.\n\n\n\nYour printed table should display the variable name, variable in the first column and the percentage of missing values, called Percent_Missing, in the second column.\nThe table should be sorted in descending order based on the percentage of missingness (Percent_Missing). If two variables have the same percentage of missingness, then they should be sorted by their variable names (variable) in ascending alphabetical order.\nYour code should print the table below\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nmissing_data &lt;- informs %&gt;%\n  summarise(across(everything(), ~sum(is.na(.))/length(.)*100, .names = \"Percent_Missing_{.col}\")) %&gt;%\n  pivot_longer(cols = starts_with(\"Percent_Missing_\"), \n               names_to = \"variable\", \n               values_to = \"Percent_Missing\") %&gt;%\n  mutate(variable = gsub(\"Percent_Missing_\", \"\", variable)) %&gt;%\n  arrange(desc(Percent_Missing), variable)\n\nprint(missing_data)\n\n# A tibble: 20 × 2\n   variable                Percent_Missing\n   &lt;chr&gt;                             &lt;dbl&gt;\n 1 comp_5_price                       98.6\n 2 comp_4_price                       94.1\n 3 comp_3_price                       83.1\n 4 comp_2_price                       60.5\n 5 comp_1_price                       35.9\n 6 comp_data_max_price                30.6\n 7 comp_data_min_price                30.6\n 8 managed_fba_stock_level            19.7\n 9 adspend                             0  \n10 cogs                                0  \n11 fba                                 0  \n12 max_price                           0  \n13 min_price                           0  \n14 price                               0  \n15 profit                              0  \n16 reffee                              0  \n17 sales                               0  \n18 salesdate                           0  \n19 sku                                 0  \n20 unitsordered                        0  \n\n\n\n\n\n\nIn this task, you are required to create a new column in the informs dataset called number_competitors. This column should contain the total number of competitors. In other words, it contains the total number of non-missing values for the competitor price variables: comp_1_price, comp_2_price, comp_3_price, comp_4_price, and comp_5_price.\n\n\n\nThe number_competitors column will have a value of 0 if there are no competitor data available for that particular row.\nIf data from only three competitors is present in a given row, then number_competitors will have a value of 3.\nAfter completing this task, your informs data frame should consist of 122,801 rows and 21 columns\n\n\ninforms$number_competitors &lt;- rowSums(!is.na(informs[, c(\"comp_1_price\", \"comp_2_price\", \"comp_3_price\", \"comp_4_price\", \"comp_5_price\")]))\n\n\n\n\n\n\nIn this task, you are required to create two new columns in the informs dataset called median_competitor_price and price_differences.\nThis first column,median_competitor_price , should contain the median price among competitors. In other words, it contains the median of non-missing values for the competitor price variables: comp_1_price, comp_2_price, comp_3_price, comp_4_price, and comp_5_price. The median_competitor_price column will have a value of NA if there are no competitor data available for that particular row.\nThe second column, price_differences should represent the difference between the company’s price (price) and the median competitor price, median_competitor_price , for each transaction (row). If there are no competitor data available for that particular row, set price_differences to NA.\nAfter completing this task, your informs data frame should consist of 122,801 rows and 23 columns.\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\ninforms &lt;- informs %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    median_competitor_price = median(c(comp_1_price, comp_2_price, comp_3_price, comp_4_price, comp_5_price), na.rm = TRUE),\n    price_differences = ifelse(is.na(median_competitor_price), NA, price - median_competitor_price)\n  )\n\nhead(informs)\n\n# A tibble: 6 × 23\n# Rowwise: \n  sku      salesdate  price unitsordered sales  cogs   fba reffee adspend profit\n  &lt;fct&gt;    &lt;date&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Envelop… 2022-01-01  29.5           19   560   236   156     84       0     84\n2 Envelop… 2022-01-02  30.0           13   390   161   107     58       0     64\n3 Envelop… 2022-01-03  29.7           84  2494  1042   690    374       0    388\n4 Envelop… 2022-01-04  29.8           78  2324   968   641    349       0    366\n5 Envelop… 2022-01-05  29.8           83  2473  1030   682    371       0    390\n6 Envelop… 2022-01-06  29.9           61  1823   757   501    273       0    292\n# ℹ 13 more variables: comp_1_price &lt;dbl&gt;, comp_2_price &lt;dbl&gt;,\n#   comp_3_price &lt;dbl&gt;, comp_4_price &lt;dbl&gt;, comp_5_price &lt;dbl&gt;,\n#   comp_data_min_price &lt;dbl&gt;, comp_data_max_price &lt;dbl&gt;,\n#   managed_fba_stock_level &lt;dbl&gt;, min_price &lt;dbl&gt;, max_price &lt;dbl&gt;,\n#   number_competitors &lt;dbl&gt;, median_competitor_price &lt;dbl&gt;,\n#   price_differences &lt;dbl&gt;\n\n\n\n\n\nIn this task, your goal is to create an R object called average_profit_vs_competitors that will store the sku and the following two variables:\n\nThe average profit per unit for each sku, called average_profit . The average_profitshould be calculated as \\(\\frac{profit}{unitsordered}\\)​.\nThe average number of competitors per sku, called average_number_competitors. The average_number_competitors for each sku should be calculated as mean(number_competitors) in R.\n\n\n\n\nCompute the average profit for each sku, labeling this new variable as average_profit.\nDouble check your calculations to make sure you do not have -Inf for average_profit values. The issue of -Inf most likely arises when unitsordered is zero, as division by zero in R returns -Inf. If unitsordered is zero for a given day and sku, you can temporarily set it to NA to avoid -Inf in average_profit calculations.\nArrange these calculated average profits in descending order for easier interpretation.\nAfter completing this task, your R object named average_profit_vs_competitors should have exactly 227 rows and 3 columns: sku, average_profit, and average_number_competitors\n\n\n# Load required library\nlibrary(dplyr)\n\naverage_profit_vs_competitors &lt;- informs %&gt;%\n  # Temporarily set unitsordered to NA where it's 0 to avoid -Inf in calculations\n  mutate(unitsordered = ifelse(unitsordered == 0, NA, unitsordered)) %&gt;%\n  # Group data by sku\n  group_by(sku) %&gt;%\n  # Calculate average profit per unit and average number of competitors\n  summarise(\n    average_profit = mean(profit / unitsordered, na.rm = TRUE),\n    average_number_competitors = mean(number_competitors, na.rm = TRUE)\n  ) %&gt;%\n\n  arrange(desc(average_profit))\n\n# Print the result\nprint(average_profit_vs_competitors)\n\n# A tibble: 227 × 3\n   sku                           average_profit average_number_competitors\n   &lt;fct&gt;                                  &lt;dbl&gt;                      &lt;dbl&gt;\n 1 Pocket Folders SKU 4                   19.0                       0.975\n 2 Classification Folders SKU 18          16.9                       0    \n 3 Pocket Folders SKU 5                   15.5                       2    \n 4 Classification Folders SKU 19          15.4                       0    \n 5 Tape SKU 8                             14.0                       0.881\n 6 Classification Folders SKU 20          13.2                       0    \n 7 Tape SKU 6                             10.3                       0    \n 8 File Folders SKU 43                     9.75                      0    \n 9 Misc School Supplies SKU 6              9.54                      3.05 \n10 Tape SKU 7                              9.39                      0    \n# ℹ 217 more rows\n\n\n\n\n\n\nIn this task, you are required to create a scatter plot using the average_profit_vs_competitors dataset and interpret it. Your plot should display the relationship between average_profit and average_number_competitors, specifically for rows where average_profit is greater than zero. Additionally, include a linear regression line on the scatter plot to gauge the overall trend.\n\n\n\nGenerate a scatter plot to display average_profit on the y-axis and average_number_competitors on the x-axis.\nOverlay a linear regression line on the scatter plot.\nFilter the data to include only rows where average_profit is greater than zero.\nLabel your axis\nInterpret your findings in one short paragraph.\n\n\nlibrary(ggplot2)\n\nfiltered_data &lt;- average_profit_vs_competitors %&gt;%\n  filter(average_profit &gt; 0)\n\nplot &lt;- ggplot(filtered_data, aes(x = average_number_competitors, y = average_profit)) +\n  geom_point(aes(color = average_profit), size = 3) +  # Scatter plot points\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +  # Linear regression line\n  labs(\n    title = \"Relationship Between Average Profit and Number of Competitors\",\n    x = \"Average Number of Competitors\",\n    y = \"Average Profit per Unit\",\n    subtitle = \"Based on SKUs with Positive Average Profit\"\n  ) +\n  theme_minimal()\n\nprint(plot)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nThe total sales revenue of a firm is calculated as the product of the price per unit and the total quantity sold. The impact of a price increase on total sales depends on the corresponding decrease in the quantity sold. In a highly competitive market, even a small increase in price can lead to a significant drop in sales, which in turn can reduce both total sales and profits.\nFor this task, please complete the following steps:\n\nCreate a subset of the informs dataset by removing rows that have no competitors. Name this new dataset informs_reduced.\nCalculate the correlation between price and profit for cases where price_differences &gt; 0 and price_differences &lt;= 0. Print and interpret your findings.\nCalculate the correlation between price and units_ordered for cases where price_differences &gt; 0 and price_differences &lt;= 0. Print and interpret your findings.\n\n\n\nlibrary(dplyr)\n\ninforms_reduced &lt;- informs %&gt;%\n  filter(number_competitors &gt; 0)\n\ncor_price_profit_positive &lt;- cor(informs_reduced %&gt;%\n                                   filter(price_differences &gt; 0) %&gt;%\n                                   select(price, profit), use = \"complete.obs\")\ncat(\"Correlation between price and profit (price_differences &gt; 0):\", cor_price_profit_positive, \"\\n\")\n\nCorrelation between price and profit (price_differences &gt; 0): 1 0.2473491 0.2473491 1 \n\ncor_price_profit_nonpositive &lt;- cor(informs_reduced %&gt;%\n                                      filter(price_differences &lt;= 0) %&gt;%\n                                      select(price, profit), use = \"complete.obs\")\ncat(\"Correlation between price and profit (price_differences &lt;= 0):\", cor_price_profit_nonpositive, \"\\n\")\n\nCorrelation between price and profit (price_differences &lt;= 0): 1 0.3082064 0.3082064 1 \n\ncor_price_units_ordered_positive &lt;- cor(informs_reduced %&gt;%\n                                          filter(price_differences &gt; 0) %&gt;%\n                                          select(price, unitsordered), use = \"complete.obs\")\ncat(\"Correlation between price and units_ordered (price_differences &gt; 0):\", cor_price_units_ordered_positive, \"\\n\")\n\nCorrelation between price and units_ordered (price_differences &gt; 0): 1 -0.02049753 -0.02049753 1 \n\ncor_price_units_ordered_nonpositive &lt;- cor(informs_reduced %&gt;%\n                                             filter(price_differences &lt;= 0) %&gt;%\n                                             select(price, unitsordered), use = \"complete.obs\")\ncat(\"Correlation between price and units_ordered (price_differences &lt;= 0):\", cor_price_units_ordered_nonpositive, \"\\n\")\n\nCorrelation between price and units_ordered (price_differences &lt;= 0): 1 0.236388 0.236388 1 \n\n\n\n\n\nBased on the correlations calculated in Task 7, we can derive the following insights:\nCorrelation between Price and Profit:\n·    When the company’s price is higher than the median competitor price (price_differences &gt; 0), the correlation between price and profit is 0.2473.\n·    When the company’s price is equal to or lower than the median competitor price (price_differences &lt;= 0), the correlation between price and profit is 0.3082.\nCorrelation between Price and Units Ordered:\n·    When the company’s price is higher than the median competitor price (price_differences &gt; 0), the correlation between price and units ordered is -0.0205, indicating a fragile negative relationship.\n·    When the company’s price is equal to or lower than the median competitor price (price_differences &lt;= 0), the correlation between price and units ordered is 0.2364.\n\n\n\nTo increase profitability, the company should consider a strategic pricing approach that balances maintaining a competitive edge and maximizing profit margins.\n1.    Competitive Pricing: For products where the company’s price is already lower or equal to the competitors (price_differences &lt;= 0), continue to monitor competitor prices closely. A slight price increase could lead to higher profits, as indicated by the positive correlation (0.3082) between price and profit in this scenario. However, be cautious to keep prices the same, as this could negatively impact the number of units ordered.\n2.    Value-Added Pricing: For products where the company’s price is higher than the competitors (price_differences &gt; 0), consider enhancing the perceived value of the product. This could be through improved product quality, customer service, or additional features. The aim is to justify the higher price point to the customers, potentially leading to increased profits without necessarily reducing the number of units ordered, as indicated by the weak negative correlation (-0.0205) between price and units ordered in this scenario.\n3.    Promotions and Discounts: Occasionally offer promotions or discounts, especially on products with high competition, to attract customers and increase sales volume. This strategy is great if it can be particularly effective if the discounts lead to a price point that is competitive with or lower than the competitors."
  },
  {
    "objectID": "posts/Test/Mini_Project_Informs_Team_10.html#introduction",
    "href": "posts/Test/Mini_Project_Informs_Team_10.html#introduction",
    "title": "Mini Project Informs Data Challenge",
    "section": "",
    "text": "This project is based on the dataset provided for the INFORMS 2023 Data Challenge. INFORMS teamed up with Blue Summit Supplies, an online retailer based in Alabama, to tackle real-world challenges in setting the right prices for their products. The eCommerce market is fast-paced, with prices changing constantly. Quick and smart pricing decisions are essential for staying competitive and profitable. The Informs data challenge aims to use the company’s actual sales data to explore how pricing impacts profits, with the goal of helping the company make better, faster pricing decisions. This projects takes a different route. As a team, your task is to understand the dataset and prepare it for further analyses.\n\nProgramming Language: R\nDeliverables: Quarto Document (.qmd) and HTML Knitted Document\nLibraries: Any libraries you deem necessary\nThere are 8 tasks, each is worth 12.5 points.\n\n\n\n\nsku: This is the product ID, a unique identifier for each product.\nsalesdate: This represents the date on which a particular product was sold.\nprice: This is the price at which the product was sold on a given day.\nunitsordered: This variable shows the number of units of a product ordered on a particular day.\nsales: This represents the total revenue generated from the sale of a product on a given day (it is calculated as the product`s price times the number of units ordered).\ncogs: This stands for “Cost of Goods Sold”, which is the direct cost incurred by the company to produce or purchase the product.\nfba: This is the eCommerce fee associated with selling the product. It includes the costs of storage, packing, and shipping handled by Amazon.\nreffee: This is the eCommerce platform fee associated with selling the product (15% of sales).\nadspend: This represents the advertisement cost associated with the product.\nprofit: This is the profit obtained from selling the product, calculated as sales minus the sum of cogs, fba, reffee, and adspend (profit = sales - cogs - fba - reffee - adspend).\ncomp_x_price: This represents the price of a similar product sold by a competitor. Up to 5 competitors` price data are available for each product (67 items have O competitors, 65 items have 1 competitor, 56 items have 2 competitors, 28 items have 3 competitors, 9 items have 4 competitors, 2 items have 5 competitors).\ncomp_data_min_price: This is the minimum price among all competitors for a similar product.\ncomp_data_max_price: This is the maximum price among all competitors for a similar product.\nmanaged_fba_stock_level: This represents the available quantity of the product in stock.\nmin_price: This is the minimum allowable selling price for the product\nmax_price: This is the maximum allowable selling price for the product.\n\n\n\n\n\ninforms &lt;- read.csv(\"2023 INFORMS BSS Data Challenge Dataset.csv\", header=TRUE)\n\n\n\n\nIn this task, you will be ensuring that all variables in the dataset informs are of the correct type. This is a crucial step in any data analysis project, as incorrect variable types can lead to misleading analyses and results.\n\n\n\nDeclare categorical variables as factors.\nConvert the date variable to a date format.\nEnsure that numerical variables are set as numerical data types.\nYour R object, informs , should have 122801 rows and 20 columns.\nPrint the data structure below with str(informs) function.\n\n\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\ninforms &lt;- informs %&gt;%\n  mutate(\n    sku = as.factor(sku),\n    salesdate = as.Date(salesdate, format=\"%Y-%m-%d\"),\n    price = as.numeric(price),\n    unitsordered = as.numeric(unitsordered),\n    sales = as.numeric(sales),\n    cogs = as.numeric(cogs),\n    fba = as.numeric(fba),\n    reffee = as.numeric(reffee),\n    adspend = as.numeric(adspend),\n    profit = as.numeric(profit),\n    comp_1_price = as.numeric(comp_1_price),\n    comp_2_price = as.numeric(comp_2_price),\n    comp_3_price = as.numeric(comp_3_price),\n    comp_4_price = as.numeric(comp_4_price),\n    comp_5_price = as.numeric(comp_5_price),\n    comp_data_min_price = as.numeric(comp_data_min_price),\n    comp_data_max_price = as.numeric(comp_data_max_price),\n    managed_fba_stock_level = as.numeric(managed_fba_stock_level),\n    min_price = as.numeric(min_price),\n    max_price = as.numeric(max_price)\n  )\n\nstr(informs)\n\n'data.frame':   122801 obs. of  20 variables:\n $ sku                    : Factor w/ 227 levels \"Binder Dividers SKU 1\",..: 61 61 61 61 61 61 61 61 61 61 ...\n $ salesdate              : Date, format: \"2022-01-01\" \"2022-01-02\" ...\n $ price                  : num  29.5 30 29.7 29.8 29.8 ...\n $ unitsordered           : num  19 13 84 78 83 61 66 18 20 70 ...\n $ sales                  : num  560 390 2494 2324 2473 ...\n $ cogs                   : num  236 161 1042 968 1030 ...\n $ fba                    : num  156 107 690 641 682 501 543 148 164 575 ...\n $ reffee                 : num  84 58 374 349 371 273 290 81 90 314 ...\n $ adspend                : num  0 0 0 0 0 0 0 0 0 0 ...\n $ profit                 : num  84 64 388 366 390 292 281 88 98 334 ...\n $ comp_1_price           : num  28.5 28.5 28.5 28.5 28.5 ...\n $ comp_2_price           : num  28 28 28 28 28 ...\n $ comp_3_price           : num  31 31 31 31 31 ...\n $ comp_4_price           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ comp_5_price           : num  NA NA NA NA NA NA NA NA NA NA ...\n $ comp_data_min_price    : num  28 28 28 28 28 ...\n $ comp_data_max_price    : num  31 31 31 31 31 ...\n $ managed_fba_stock_level: num  NA NA NA NA NA NA NA NA NA NA ...\n $ min_price              : num  28 28 28 28 28 ...\n $ max_price              : num  35 35 35 35 35 ...\n\n\n\n\n\n\nIn this task, you are required to calculate the percentage of missing values for each variable in the informs dataset and display the results in a table. Understanding the extent of missing data is a crucial step in data analysis, as it can significantly impact the results.\n\n\n\nYour printed table should display the variable name, variable in the first column and the percentage of missing values, called Percent_Missing, in the second column.\nThe table should be sorted in descending order based on the percentage of missingness (Percent_Missing). If two variables have the same percentage of missingness, then they should be sorted by their variable names (variable) in ascending alphabetical order.\nYour code should print the table below\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\nmissing_data &lt;- informs %&gt;%\n  summarise(across(everything(), ~sum(is.na(.))/length(.)*100, .names = \"Percent_Missing_{.col}\")) %&gt;%\n  pivot_longer(cols = starts_with(\"Percent_Missing_\"), \n               names_to = \"variable\", \n               values_to = \"Percent_Missing\") %&gt;%\n  mutate(variable = gsub(\"Percent_Missing_\", \"\", variable)) %&gt;%\n  arrange(desc(Percent_Missing), variable)\n\nprint(missing_data)\n\n# A tibble: 20 × 2\n   variable                Percent_Missing\n   &lt;chr&gt;                             &lt;dbl&gt;\n 1 comp_5_price                       98.6\n 2 comp_4_price                       94.1\n 3 comp_3_price                       83.1\n 4 comp_2_price                       60.5\n 5 comp_1_price                       35.9\n 6 comp_data_max_price                30.6\n 7 comp_data_min_price                30.6\n 8 managed_fba_stock_level            19.7\n 9 adspend                             0  \n10 cogs                                0  \n11 fba                                 0  \n12 max_price                           0  \n13 min_price                           0  \n14 price                               0  \n15 profit                              0  \n16 reffee                              0  \n17 sales                               0  \n18 salesdate                           0  \n19 sku                                 0  \n20 unitsordered                        0  \n\n\n\n\n\n\nIn this task, you are required to create a new column in the informs dataset called number_competitors. This column should contain the total number of competitors. In other words, it contains the total number of non-missing values for the competitor price variables: comp_1_price, comp_2_price, comp_3_price, comp_4_price, and comp_5_price.\n\n\n\nThe number_competitors column will have a value of 0 if there are no competitor data available for that particular row.\nIf data from only three competitors is present in a given row, then number_competitors will have a value of 3.\nAfter completing this task, your informs data frame should consist of 122,801 rows and 21 columns\n\n\ninforms$number_competitors &lt;- rowSums(!is.na(informs[, c(\"comp_1_price\", \"comp_2_price\", \"comp_3_price\", \"comp_4_price\", \"comp_5_price\")]))\n\n\n\n\n\n\nIn this task, you are required to create two new columns in the informs dataset called median_competitor_price and price_differences.\nThis first column,median_competitor_price , should contain the median price among competitors. In other words, it contains the median of non-missing values for the competitor price variables: comp_1_price, comp_2_price, comp_3_price, comp_4_price, and comp_5_price. The median_competitor_price column will have a value of NA if there are no competitor data available for that particular row.\nThe second column, price_differences should represent the difference between the company’s price (price) and the median competitor price, median_competitor_price , for each transaction (row). If there are no competitor data available for that particular row, set price_differences to NA.\nAfter completing this task, your informs data frame should consist of 122,801 rows and 23 columns.\n\n\n\nlibrary(dplyr)\nlibrary(tidyr)\n\ninforms &lt;- informs %&gt;%\n  rowwise() %&gt;%\n  mutate(\n    median_competitor_price = median(c(comp_1_price, comp_2_price, comp_3_price, comp_4_price, comp_5_price), na.rm = TRUE),\n    price_differences = ifelse(is.na(median_competitor_price), NA, price - median_competitor_price)\n  )\n\nhead(informs)\n\n# A tibble: 6 × 23\n# Rowwise: \n  sku      salesdate  price unitsordered sales  cogs   fba reffee adspend profit\n  &lt;fct&gt;    &lt;date&gt;     &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n1 Envelop… 2022-01-01  29.5           19   560   236   156     84       0     84\n2 Envelop… 2022-01-02  30.0           13   390   161   107     58       0     64\n3 Envelop… 2022-01-03  29.7           84  2494  1042   690    374       0    388\n4 Envelop… 2022-01-04  29.8           78  2324   968   641    349       0    366\n5 Envelop… 2022-01-05  29.8           83  2473  1030   682    371       0    390\n6 Envelop… 2022-01-06  29.9           61  1823   757   501    273       0    292\n# ℹ 13 more variables: comp_1_price &lt;dbl&gt;, comp_2_price &lt;dbl&gt;,\n#   comp_3_price &lt;dbl&gt;, comp_4_price &lt;dbl&gt;, comp_5_price &lt;dbl&gt;,\n#   comp_data_min_price &lt;dbl&gt;, comp_data_max_price &lt;dbl&gt;,\n#   managed_fba_stock_level &lt;dbl&gt;, min_price &lt;dbl&gt;, max_price &lt;dbl&gt;,\n#   number_competitors &lt;dbl&gt;, median_competitor_price &lt;dbl&gt;,\n#   price_differences &lt;dbl&gt;\n\n\n\n\n\nIn this task, your goal is to create an R object called average_profit_vs_competitors that will store the sku and the following two variables:\n\nThe average profit per unit for each sku, called average_profit . The average_profitshould be calculated as \\(\\frac{profit}{unitsordered}\\)​.\nThe average number of competitors per sku, called average_number_competitors. The average_number_competitors for each sku should be calculated as mean(number_competitors) in R.\n\n\n\n\nCompute the average profit for each sku, labeling this new variable as average_profit.\nDouble check your calculations to make sure you do not have -Inf for average_profit values. The issue of -Inf most likely arises when unitsordered is zero, as division by zero in R returns -Inf. If unitsordered is zero for a given day and sku, you can temporarily set it to NA to avoid -Inf in average_profit calculations.\nArrange these calculated average profits in descending order for easier interpretation.\nAfter completing this task, your R object named average_profit_vs_competitors should have exactly 227 rows and 3 columns: sku, average_profit, and average_number_competitors\n\n\n# Load required library\nlibrary(dplyr)\n\naverage_profit_vs_competitors &lt;- informs %&gt;%\n  # Temporarily set unitsordered to NA where it's 0 to avoid -Inf in calculations\n  mutate(unitsordered = ifelse(unitsordered == 0, NA, unitsordered)) %&gt;%\n  # Group data by sku\n  group_by(sku) %&gt;%\n  # Calculate average profit per unit and average number of competitors\n  summarise(\n    average_profit = mean(profit / unitsordered, na.rm = TRUE),\n    average_number_competitors = mean(number_competitors, na.rm = TRUE)\n  ) %&gt;%\n\n  arrange(desc(average_profit))\n\n# Print the result\nprint(average_profit_vs_competitors)\n\n# A tibble: 227 × 3\n   sku                           average_profit average_number_competitors\n   &lt;fct&gt;                                  &lt;dbl&gt;                      &lt;dbl&gt;\n 1 Pocket Folders SKU 4                   19.0                       0.975\n 2 Classification Folders SKU 18          16.9                       0    \n 3 Pocket Folders SKU 5                   15.5                       2    \n 4 Classification Folders SKU 19          15.4                       0    \n 5 Tape SKU 8                             14.0                       0.881\n 6 Classification Folders SKU 20          13.2                       0    \n 7 Tape SKU 6                             10.3                       0    \n 8 File Folders SKU 43                     9.75                      0    \n 9 Misc School Supplies SKU 6              9.54                      3.05 \n10 Tape SKU 7                              9.39                      0    \n# ℹ 217 more rows\n\n\n\n\n\n\nIn this task, you are required to create a scatter plot using the average_profit_vs_competitors dataset and interpret it. Your plot should display the relationship between average_profit and average_number_competitors, specifically for rows where average_profit is greater than zero. Additionally, include a linear regression line on the scatter plot to gauge the overall trend.\n\n\n\nGenerate a scatter plot to display average_profit on the y-axis and average_number_competitors on the x-axis.\nOverlay a linear regression line on the scatter plot.\nFilter the data to include only rows where average_profit is greater than zero.\nLabel your axis\nInterpret your findings in one short paragraph.\n\n\nlibrary(ggplot2)\n\nfiltered_data &lt;- average_profit_vs_competitors %&gt;%\n  filter(average_profit &gt; 0)\n\nplot &lt;- ggplot(filtered_data, aes(x = average_number_competitors, y = average_profit)) +\n  geom_point(aes(color = average_profit), size = 3) +  # Scatter plot points\n  geom_smooth(method = \"lm\", se = FALSE, color = \"blue\") +  # Linear regression line\n  labs(\n    title = \"Relationship Between Average Profit and Number of Competitors\",\n    x = \"Average Number of Competitors\",\n    y = \"Average Profit per Unit\",\n    subtitle = \"Based on SKUs with Positive Average Profit\"\n  ) +\n  theme_minimal()\n\nprint(plot)\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\nThe total sales revenue of a firm is calculated as the product of the price per unit and the total quantity sold. The impact of a price increase on total sales depends on the corresponding decrease in the quantity sold. In a highly competitive market, even a small increase in price can lead to a significant drop in sales, which in turn can reduce both total sales and profits.\nFor this task, please complete the following steps:\n\nCreate a subset of the informs dataset by removing rows that have no competitors. Name this new dataset informs_reduced.\nCalculate the correlation between price and profit for cases where price_differences &gt; 0 and price_differences &lt;= 0. Print and interpret your findings.\nCalculate the correlation between price and units_ordered for cases where price_differences &gt; 0 and price_differences &lt;= 0. Print and interpret your findings.\n\n\n\nlibrary(dplyr)\n\ninforms_reduced &lt;- informs %&gt;%\n  filter(number_competitors &gt; 0)\n\ncor_price_profit_positive &lt;- cor(informs_reduced %&gt;%\n                                   filter(price_differences &gt; 0) %&gt;%\n                                   select(price, profit), use = \"complete.obs\")\ncat(\"Correlation between price and profit (price_differences &gt; 0):\", cor_price_profit_positive, \"\\n\")\n\nCorrelation between price and profit (price_differences &gt; 0): 1 0.2473491 0.2473491 1 \n\ncor_price_profit_nonpositive &lt;- cor(informs_reduced %&gt;%\n                                      filter(price_differences &lt;= 0) %&gt;%\n                                      select(price, profit), use = \"complete.obs\")\ncat(\"Correlation between price and profit (price_differences &lt;= 0):\", cor_price_profit_nonpositive, \"\\n\")\n\nCorrelation between price and profit (price_differences &lt;= 0): 1 0.3082064 0.3082064 1 \n\ncor_price_units_ordered_positive &lt;- cor(informs_reduced %&gt;%\n                                          filter(price_differences &gt; 0) %&gt;%\n                                          select(price, unitsordered), use = \"complete.obs\")\ncat(\"Correlation between price and units_ordered (price_differences &gt; 0):\", cor_price_units_ordered_positive, \"\\n\")\n\nCorrelation between price and units_ordered (price_differences &gt; 0): 1 -0.02049753 -0.02049753 1 \n\ncor_price_units_ordered_nonpositive &lt;- cor(informs_reduced %&gt;%\n                                             filter(price_differences &lt;= 0) %&gt;%\n                                             select(price, unitsordered), use = \"complete.obs\")\ncat(\"Correlation between price and units_ordered (price_differences &lt;= 0):\", cor_price_units_ordered_nonpositive, \"\\n\")\n\nCorrelation between price and units_ordered (price_differences &lt;= 0): 1 0.236388 0.236388 1 \n\n\n\n\n\nBased on the correlations calculated in Task 7, we can derive the following insights:\nCorrelation between Price and Profit:\n·    When the company’s price is higher than the median competitor price (price_differences &gt; 0), the correlation between price and profit is 0.2473.\n·    When the company’s price is equal to or lower than the median competitor price (price_differences &lt;= 0), the correlation between price and profit is 0.3082.\nCorrelation between Price and Units Ordered:\n·    When the company’s price is higher than the median competitor price (price_differences &gt; 0), the correlation between price and units ordered is -0.0205, indicating a fragile negative relationship.\n·    When the company’s price is equal to or lower than the median competitor price (price_differences &lt;= 0), the correlation between price and units ordered is 0.2364.\n\n\n\nTo increase profitability, the company should consider a strategic pricing approach that balances maintaining a competitive edge and maximizing profit margins.\n1.    Competitive Pricing: For products where the company’s price is already lower or equal to the competitors (price_differences &lt;= 0), continue to monitor competitor prices closely. A slight price increase could lead to higher profits, as indicated by the positive correlation (0.3082) between price and profit in this scenario. However, be cautious to keep prices the same, as this could negatively impact the number of units ordered.\n2.    Value-Added Pricing: For products where the company’s price is higher than the competitors (price_differences &gt; 0), consider enhancing the perceived value of the product. This could be through improved product quality, customer service, or additional features. The aim is to justify the higher price point to the customers, potentially leading to increased profits without necessarily reducing the number of units ordered, as indicated by the weak negative correlation (-0.0205) between price and units ordered in this scenario.\n3.    Promotions and Discounts: Occasionally offer promotions or discounts, especially on products with high competition, to attract customers and increase sales volume. This strategy is great if it can be particularly effective if the discounts lead to a price point that is competitive with or lower than the competitors."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jose A Rodriguez",
    "section": "",
    "text": "Mini Project Informs Data Challenge\n\n\n\n\n\n\n\nCode\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2023\n\n\nJose A Rodriguez\n\n\n\n\n\n\n  \n\n\n\n\nLinear Regression vs Generalized Additive Models\n\n\n\n\n\n\n\nCode\n\n\nAnalysis\n\n\n\n\n\n\n\n\n\n\n\nDec 7, 2023\n\n\nJose A Rodriguez\n\n\n\n\n\n\nNo matching items"
  }
]